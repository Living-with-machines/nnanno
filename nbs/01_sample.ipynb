{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample\n",
    "\n",
    "> Create samples from Newspaper navigator dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\ # TODO Intro to module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nnanno.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# TODO tidy imports\n",
    "\n",
    "# sys \n",
    "import io\n",
    "import shutil\n",
    "import pkg_resources\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# other\n",
    "from tqdm.auto import trange, tqdm\n",
    "import requests\n",
    "import ijson\n",
    "import functools\n",
    "import math\n",
    "from cytoolz import dicttoolz, itertoolz\n",
    "import random\n",
    "import json\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "import itertools\n",
    "from pandas import json_normalize\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "# typing\n",
    "from typing import (\n",
    "    Any,\n",
    "    Optional,\n",
    "    Union,\n",
    "    Dict,\n",
    "    List,\n",
    "    Tuple,\n",
    "    Set,\n",
    "    Iterable,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_json_url(year: Union[str,int], kind:str='photos') -> str:\n",
    "    '''Returns url for the json data from news-navigator for given `year` and `kind`'''\n",
    "    return f'https://news-navigator.labs.loc.gov/prepackaged/{year}_{kind}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_json_url(1860) == 'https://news-navigator.labs.loc.gov/prepackaged/1860_photos.json' \n",
    "assert get_json_url(1950) == 'https://news-navigator.labs.loc.gov/prepackaged/1950_photos.json' \n",
    "assert get_json_url(1950,'ads') == 'https://news-navigator.labs.loc.gov/prepackaged/1950_ads.json' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_json(url) -> Dict[str, Any]:\n",
    "    \"\"\"Returns loaded json from url\n",
    "\n",
    "    Parameters:\n",
    "    url (str): URL for news-navigator json file\n",
    "\n",
    "    Returns:\n",
    "    Dict: dictionary with data from input json url\n",
    "    \"\"\"\n",
    "    with requests.get(url, timeout=2) as r:\n",
    "        r.raise_for_status()\n",
    "        return json.loads(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_json = load_json('https://news-navigator.labs.loc.gov/prepackaged/1950_photos.json')\n",
    "assert type(test_json[0]) == dict\n",
    "assert type(test_json) == list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works well for a smallish file but if we try this with the [1905_ads.json](https://news-navigator.labs.loc.gov/prepackaged/1910_ads.json) file which is ~3.3GB we will likely run out of memory. For example running \n",
    "\n",
    "```python\n",
    "with requests.get('https://news-navigator.labs.loc.gov/prepackaged/1910_ads.json') as r:\n",
    "    data = json.loads(r.content)\n",
    "len(data)\n",
    "```\n",
    "\n",
    "on a Google Colab instance with 25GB of RAM causes a crash. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@functools.lru_cache(256)\n",
    "def count_json_iter(url: str, session=None) -> int:\n",
    "    \"\"\"\n",
    "    Returns count of objects in url json file using an iterator to avoid loading json          into memory\n",
    "\n",
    "    Parameters:\n",
    "    url (str): URL for news-navigator json file\n",
    "\n",
    "    Returns:\n",
    "    int: count of json objects in url\n",
    "    \"\"\"\n",
    "    if not session:\n",
    "        session = create_cached_session()\n",
    "    with session.get(url, timeout=60) as r:\n",
    "        r.raise_for_status()\n",
    "        if r:\n",
    "            objects = ijson.items(r.content, \"item\")\n",
    "            count = itertoolz.count(iter(objects))\n",
    "        else:\n",
    "            count = np.nan\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_json_iter('https://news-navigator.labs.loc.gov/prepackaged/1850_photos.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://news-navigator.labs.loc.gov/prepackaged/1850_photos.json'\n",
    "assert type(count_json_iter(url)) == int\n",
    "assert len(json.loads(requests.get(url).content)) == count_json_iter(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@functools.lru_cache(256)\n",
    "def get_year_size(year,kind):\n",
    "    session = None\n",
    "    dset_size = {}       \n",
    "    url = get_json_url(year,kind)\n",
    "    if kind == ('ads' or 'headlines') and int(year) >=1870:\n",
    "        session = create_session()\n",
    "    dset_size[str(year)] = count_json_iter(url, session)\n",
    "    return dset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1850': 22}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_year_size(1850, 'photos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@functools.lru_cache(512)\n",
    "def get_year_sizes(kind,start=1850, end=1950, step=5):\n",
    "    \"\"\"\n",
    "    Returns the sizes for json data files for `kind` between year `start` and `end`    \n",
    "    with step size 'step'\n",
    "\n",
    "    Parameters:\n",
    "    kind (str): kind of image from news-navigator options:\n",
    "    photos, illustrations, maps, comics, cartoons, headlines, ads\n",
    "\n",
    "    Returns:\n",
    "    Pandas.DataFrame: with data from input json url\n",
    "    \"\"\"\n",
    "  #  dset_size = {}\n",
    "    futures = []\n",
    "    years = range(start,end+1,step)\n",
    "    max_workers = get_max_workers(years)\n",
    "    with tqdm(total=len(years)) as progress:\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            for year in years:\n",
    "                future = executor.submit(get_year_size, year, kind)\n",
    "                future.add_done_callback(lambda p: progress.update())\n",
    "                futures.append(future)\n",
    "        results = [future.result() for future in futures]\n",
    "        dset_size = {k: v for d in results for k, v in d.items()}\n",
    "    year_df = pd.DataFrame.from_dict(dset_size,orient='index',columns=[f'{kind}_count'])\n",
    "    return year_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the year sizes for a given kind taking a step size `step`. For example to get the number of photos in the news-navigator dataset between 1850 and 1860 for every year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 146.76it/s]CPU times: user 26.7 ms, sys: 21.3 ms, total: 48 ms\n",
      "Wall time: 44.1 ms\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photos_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      photos_count\n",
       "1850            22\n",
       "1851            20\n",
       "1852            22\n",
       "1853            45\n",
       "1854           221\n",
       "1855            17"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_year_sizes('photos',1850, 1855, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 249.65it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 6180.21it/s]\n"
     ]
    }
   ],
   "source": [
    "assert len(get_year_sizes('photos',1850, 1860, step=1)) == 11\n",
    "assert len(get_year_sizes('photos',1850,1860, step=2)) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_all_year_sizes(start=1850, end=1950,step=1, save:bool=True):\n",
    "    \"\"\"\n",
    "    Returns a dataframe with number of counts from year `start` to `end`\n",
    "    \"\"\"\n",
    "    kinds = ['ads', 'photos', 'maps', 'illustrations', 'comics', 'cartoons','headlines']\n",
    "    dfs = []\n",
    "    for kind in tqdm(kinds):\n",
    "        df = get_year_sizes(kind, start=start, end=end,step=step)\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs, axis=1)\n",
    "    df['total'] = df.sum(axis=1)\n",
    "    if save:\n",
    "        df.to_csv('all_year_sizes.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming sampling\n",
    "\n",
    "Since we want a subset of the Newspaper Navigator datasets which we can either work with for [annotation](!TODO add link) or for inference we want to create samples. Sampling in python can be complicated depending on the type of population you are working with and the properties your sample needs to have but usually we can do something fairly simple like. For example, if we want to sample from a selection of books we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['War and Peace']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "books = ['War and Peace', 'Frankenstein', 'If They Come in the Morning']\n",
    "random.sample(books, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we run into a same problem as when trying to get the length of a json dataset which wouldn't fit into memory above. For example if we want to sample $k$ examples from one of our json files which we can't load into memory. To get around this we can use [Reservoir_sampling](https://en.wikipedia.org/wiki/Reservoir_sampling):\n",
    "\n",
    "> Reservoir sampling is a family of randomized algorithms for choosing a simple random sample without replacement of k items from a population of unknown size n in a single pass over the items. The size of the population n is not known to the algorithm and is typically too large to fit all n items into main memory. The population is revealed to the algorithm over time, and the algorithm cannot look back at previous items. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sample_stream(stream, k:int):\n",
    "    \"\"\"\n",
    "    Return a random sample of k elements drawn without replacement from stream.\n",
    "    Designed to be used when the elements of stream cannot easily fit into memory.\n",
    "    \"\"\"\n",
    "    r = np.array(list(itertools.islice(stream, k)))\n",
    "    for t, x in enumerate(stream, k + 1):\n",
    "        i = np.random.randint(1, t + 1)\n",
    "\n",
    "        if i <= k:\n",
    "            r[i - 1] = x\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we sample whilst only loading a small numer of items into memory at one time. This does come at some cost, mainly speed. There are faster ways of sampling from a stream but this isn't the main bottle neck for sampling in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6692, 27245, 30762, 81424, 96297])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_stream(range(1,100000), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Karl Marx', 'CLR James'], dtype='<U14')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['Karl Marx', 'Rosa Luxenburg', 'Raya Dunayevskaya', 'CLR James']\n",
    "sample_stream(iter(names), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert len(sample_stream(range(1,100),5)) == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@functools.lru_cache(128)\n",
    "def calc_frac_size(url,frac):\n",
    "    \"returns fraction size from a json stream\"\n",
    "    return round(count_json_iter(url)*frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "url = get_json_url(1850)\n",
    "assert calc_frac_size(url, 0.5)== 11 #22*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calc_year_from_total(total,start,end,step):\n",
    "    \"Calculate size of a year sample based on a total sample size\"\n",
    "    return max(1,round(total/(((end-start)+1)/step)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_year_from_total(10,1850, 18950,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "assert calc_year_from_total(10, 1850,1950,1) >=1 # test that a value is always returned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def reduce_df_memory(df):\n",
    "    return df.astype(\n",
    "            {\"score\": \"float64\",\n",
    "                \"page_seq_num\": \"int32\",\n",
    "                \"batch\": \"category\",\n",
    "                \"box\":\"object\",\n",
    "                \"lccn\": \"category\",\n",
    "                \"page_url\": \"category\",\n",
    "                \"name\": \"category\",\n",
    "                \"publisher\": \"category\",\n",
    "                \"place_of_publication\": \"category\",\n",
    "                \"edition_seq_num\": \"category\"}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def sample_year(kind:str,sample_size:Union[int,float], year:int) ->np.array:\n",
    "    url = get_json_url(year, kind)\n",
    "    if type(sample_size) is float:\n",
    "        sample_size = calc_frac_size(url, sample_size)\n",
    "    if kind == ('ads' or 'headlines') and int(year) >=1870:\n",
    "        session = create_session()\n",
    "    else:\n",
    "        session = create_cached_session()\n",
    "    with session.get(get_json_url(year, kind)) as r:\n",
    "        if r:\n",
    "            try:\n",
    "                data = ijson.items(r.content, \"item\")\n",
    "                sample_data = sample_stream(iter(data), sample_size)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                sample_data = np.nan\n",
    "    return sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'filepath': 'ohi_ingstad_ver01/data/sn85026051/00296027029/1850090701/0061/002_0_90.jpg', 'pub_date': '1850-09-07', 'page_seq_num': 61, 'edition_seq_num': 1, 'batch': 'ohi_ingstad_ver01', 'lccn': 'sn85026051', 'box': [Decimal('0.5714432636546668'), Decimal('0.6112432110852859'), Decimal('0.7022799185194107'), Decimal('0.7229990545061264')], 'score': Decimal('0.9038882255554199'), 'ocr': [',', 'COME', 'IN,', 'WE', 'CALL', 'YOU', '!'], 'place_of_publication': 'Fremont, Sandusky County, Ohio', 'geographic_coverage': ['Ohio--Sandusky--Fremont'], 'name': 'Fremont weekly freeman. [volume]', 'publisher': 'J.S. Fouke', 'url': 'https://news-navigator.labs.loc.gov/data/ohi_ingstad_ver01/data/sn85026051/00296027029/1850090701/0061/002_0_90.jpg', 'page_url': 'https://chroniclingamerica.loc.gov/data/batches/ohi_ingstad_ver01/data/sn85026051/00296027029/1850090701/0061.jp2'}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_year('photos', 1, 1850)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class nnSampler:\n",
    "    def __init__(self):\n",
    "        self.population = pd.read_csv(pkg_resources.resource_stream('nnanno', 'data/all_year_counts.csv'), \n",
    "                                      index_col=0)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f'{self.__class__.__name__}')\n",
    "        \n",
    "\n",
    "    def create_sample(\n",
    "        self,\n",
    "        sample_size: Union[int, float],\n",
    "        kind: str = \"photos\",\n",
    "        start_year: int = 1850,\n",
    "        end_year: int = 1950,\n",
    "        step: int = 5,\n",
    "        year_sample=True,\n",
    "        save: bool = False,\n",
    "        reduce_memory=True,\n",
    "    ):\n",
    "        if not year_sample:\n",
    "            if not type(sample_size) == int:\n",
    "                raise ValueError(\n",
    "                    f\"type{sample_size} is not an int. Fractions are only supported for sampling by year\"\n",
    "                )\n",
    "            sample_size = calc_year_from_total(sample_size, start_year, end_year, step)\n",
    "        futures = []\n",
    "        years = range(start_year, end_year + 1, step)\n",
    "        _year_sample = partial(sample_year, kind, sample_size)\n",
    "        with tqdm(total=len(years)) as progress:\n",
    "            with concurrent.futures.ThreadPoolExecutor(2) as executor:\n",
    "                for year in years:\n",
    "                    future = executor.submit(_year_sample, year)\n",
    "                    future.add_done_callback(lambda p: progress.update())\n",
    "                    futures.append(future)\n",
    "        results = [future.result() for future in futures]\n",
    "        df = pd.DataFrame.from_dict(list(itertoolz.concat(results)))\n",
    "\n",
    "        if reduce_memory:\n",
    "            df = reduce_df_memory(df)\n",
    "        if save:\n",
    "            df.to_json(f\"{kind}_{start_year}_{end_year}_sample.json\")\n",
    "        self.sample = df\n",
    "        return df\n",
    "\n",
    "    def download_sample(\n",
    "        self,\n",
    "        out_dir,\n",
    "        csv_name=None,\n",
    "        df=None,\n",
    "        original: bool = True,\n",
    "        pct: int = None,\n",
    "        size: tuple = None,\n",
    "        preserve_asp_ratio: bool = True,\n",
    "    ):\n",
    "        if df is not None:\n",
    "            self.download_df = df.copy(deep=True)\n",
    "        else:\n",
    "            try:\n",
    "                self.download_df = self.sample.copy(deep=True)\n",
    "            except AttributeError as E:\n",
    "                print(\n",
    "                    \"You need to create a sample before downloading, or pass in a previously created \"\n",
    "                )\n",
    "        self.download_df[\"iiif_url\"] = self.download_df.apply(\n",
    "            lambda x: iif_df_apply(\n",
    "                x,\n",
    "                original=original,\n",
    "                pct=pct,\n",
    "                size=size,\n",
    "                preserve_asp_ratio=preserve_asp_ratio,\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        self.download_df[\"download_image_path\"] = self.download_df['filepath'].str.replace('/','_')\n",
    "        \n",
    "        if not Path(out_dir).exists():\n",
    "            Path(out_dir).mkdir(parents=True)\n",
    "        _download_image = lambda x: download_image(\n",
    "            x.iiif_url, x.download_image_path, out_dir)\n",
    "        with tqdm(total=len(self.download_df)) as progress:\n",
    "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "                futures = []\n",
    "                for tuple_row in self.download_df.itertuples():\n",
    "                    future = executor.submit(_download_image, tuple_row)\n",
    "                    future.add_done_callback(lambda p: progress.update())\n",
    "                    futures.append(future)\n",
    "                del futures\n",
    "        if csv_name is None:\n",
    "            today = datetime.today()\n",
    "            time_stamp = today.strftime(\"%Y_%d_%m_%H_%M\")\n",
    "            csv_name = f\"{time_stamp}_{len(self.download_df)}_sample\"\n",
    "        #self.download_df.to_csv(f'{out_dir}/{csv_name}.csv')\n",
    "        self.download_df.to_json(f'{out_dir}/{csv_name}.json') # TODO make sure to use json for saving outputs of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = nnSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnSampler"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ads_count</th>\n",
       "      <th>photos_count</th>\n",
       "      <th>maps_count</th>\n",
       "      <th>illustrations_count</th>\n",
       "      <th>comics_count</th>\n",
       "      <th>cartoons_count</th>\n",
       "      <th>headlines_count</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>8841</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>671</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>11243</td>\n",
       "      <td>20791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>10065</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>457</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>12262</td>\n",
       "      <td>22817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>8764</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>671</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>13524</td>\n",
       "      <td>23009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>11517</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>1106</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>13224</td>\n",
       "      <td>25986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>15050</td>\n",
       "      <td>221</td>\n",
       "      <td>15</td>\n",
       "      <td>732</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>15282</td>\n",
       "      <td>31314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>185139</td>\n",
       "      <td>5945</td>\n",
       "      <td>1857</td>\n",
       "      <td>1053</td>\n",
       "      <td>3280</td>\n",
       "      <td>861</td>\n",
       "      <td>68275</td>\n",
       "      <td>266410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>181223</td>\n",
       "      <td>4188</td>\n",
       "      <td>1750</td>\n",
       "      <td>1115</td>\n",
       "      <td>3630</td>\n",
       "      <td>797</td>\n",
       "      <td>57018</td>\n",
       "      <td>249721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>152987</td>\n",
       "      <td>4282</td>\n",
       "      <td>1359</td>\n",
       "      <td>1154</td>\n",
       "      <td>3031</td>\n",
       "      <td>624</td>\n",
       "      <td>43432</td>\n",
       "      <td>206869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>154510</td>\n",
       "      <td>6015</td>\n",
       "      <td>1888</td>\n",
       "      <td>1280</td>\n",
       "      <td>3356</td>\n",
       "      <td>634</td>\n",
       "      <td>42904</td>\n",
       "      <td>210587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>154961</td>\n",
       "      <td>5630</td>\n",
       "      <td>1952</td>\n",
       "      <td>1223</td>\n",
       "      <td>3893</td>\n",
       "      <td>704</td>\n",
       "      <td>37854</td>\n",
       "      <td>206217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ads_count  photos_count  maps_count  illustrations_count  comics_count  \\\n",
       "1850       8841            22           5                  671             9   \n",
       "1851      10065            20           6                  457             7   \n",
       "1852       8764            22          10                  671            10   \n",
       "1853      11517            45           5                 1106            88   \n",
       "1854      15050           221          15                  732            11   \n",
       "...         ...           ...         ...                  ...           ...   \n",
       "1946     185139          5945        1857                 1053          3280   \n",
       "1947     181223          4188        1750                 1115          3630   \n",
       "1948     152987          4282        1359                 1154          3031   \n",
       "1949     154510          6015        1888                 1280          3356   \n",
       "1950     154961          5630        1952                 1223          3893   \n",
       "\n",
       "      cartoons_count  headlines_count   total  \n",
       "1850               0            11243   20791  \n",
       "1851               0            12262   22817  \n",
       "1852               8            13524   23009  \n",
       "1853               1            13224   25986  \n",
       "1854               3            15282   31314  \n",
       "...              ...              ...     ...  \n",
       "1946             861            68275  266410  \n",
       "1947             797            57018  249721  \n",
       "1948             624            43432  206869  \n",
       "1949             634            42904  210587  \n",
       "1950             704            37854  206217  \n",
       "\n",
       "[101 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler.population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 135.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>page_seq_num</th>\n",
       "      <th>edition_seq_num</th>\n",
       "      <th>batch</th>\n",
       "      <th>lccn</th>\n",
       "      <th>box</th>\n",
       "      <th>score</th>\n",
       "      <th>ocr</th>\n",
       "      <th>place_of_publication</th>\n",
       "      <th>geographic_coverage</th>\n",
       "      <th>name</th>\n",
       "      <th>publisher</th>\n",
       "      <th>url</th>\n",
       "      <th>page_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>msar_icydrop_ver05/data/sn83016872/00295878502...</td>\n",
       "      <td>1850-12-31</td>\n",
       "      <td>986</td>\n",
       "      <td>1</td>\n",
       "      <td>msar_icydrop_ver05</td>\n",
       "      <td>sn83016872</td>\n",
       "      <td>[0.1624672249571918, 0.026467160391487225, 0.9...</td>\n",
       "      <td>0.963962</td>\n",
       "      <td>[k'.'-vk'', t', :j, 1, !'V1, kkk, .0, :I, .Ii:...</td>\n",
       "      <td>Canton, Miss.</td>\n",
       "      <td>[Mississippi--Madison--Canton]</td>\n",
       "      <td>The Mississippi Creole. [volume]</td>\n",
       "      <td>M.N. Prewett</td>\n",
       "      <td>https://news-navigator.labs.loc.gov/data/msar_...</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ohi_ingstad_ver01/data/sn85026051/00296027029/...</td>\n",
       "      <td>1850-07-20</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>ohi_ingstad_ver01</td>\n",
       "      <td>sn85026051</td>\n",
       "      <td>[0.3009427797781111, 0.6294158908847332, 0.433...</td>\n",
       "      <td>0.929614</td>\n",
       "      <td>[L, -, COME, IN,, WE, CALL, YOU, !, .v';:]</td>\n",
       "      <td>Fremont, Sandusky County, Ohio</td>\n",
       "      <td>[Ohio--Sandusky--Fremont]</td>\n",
       "      <td>Fremont weekly freeman. [volume]</td>\n",
       "      <td>J.S. Fouke</td>\n",
       "      <td>https://news-navigator.labs.loc.gov/data/ohi_i...</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ohi_ingstad_ver01/data/sn85026051/00296027029/...</td>\n",
       "      <td>1850-08-24</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>ohi_ingstad_ver01</td>\n",
       "      <td>sn85026051</td>\n",
       "      <td>[0.4334465613731971, 0.6177851558250381, 0.565...</td>\n",
       "      <td>0.979533</td>\n",
       "      <td>[COME, IN,, WE, CALL, YOU!]</td>\n",
       "      <td>Fremont, Sandusky County, Ohio</td>\n",
       "      <td>[Ohio--Sandusky--Fremont]</td>\n",
       "      <td>Fremont weekly freeman. [volume]</td>\n",
       "      <td>J.S. Fouke</td>\n",
       "      <td>https://news-navigator.labs.loc.gov/data/ohi_i...</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ncu_hawk_ver02/data/sn84026472/00416156360/185...</td>\n",
       "      <td>1850-05-22</td>\n",
       "      <td>289</td>\n",
       "      <td>1</td>\n",
       "      <td>ncu_hawk_ver02</td>\n",
       "      <td>sn84026472</td>\n",
       "      <td>[0.6732673909317263, 0.042179068056539225, 0.8...</td>\n",
       "      <td>0.914908</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hillsborough, N.C.</td>\n",
       "      <td>[North Carolina--Orange--Hillsboro]</td>\n",
       "      <td>The Hillsborough recorder. [volume]</td>\n",
       "      <td>Dennis Heartt</td>\n",
       "      <td>https://news-navigator.labs.loc.gov/data/ncu_h...</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vtu_londonderry_ver01/data/sn84023252/00200296...</td>\n",
       "      <td>1850-03-09</td>\n",
       "      <td>247</td>\n",
       "      <td>1</td>\n",
       "      <td>vtu_londonderry_ver01</td>\n",
       "      <td>sn84023252</td>\n",
       "      <td>[0.5134230714407026, 0.1490311215403323, 0.669...</td>\n",
       "      <td>0.922406</td>\n",
       "      <td>[OU1, Dr., Jftcob, Townaond.]</td>\n",
       "      <td>St. Johnsbury, Vt.</td>\n",
       "      <td>[Vermont--Caledonia--Saint Johnsbury]</td>\n",
       "      <td>The Caledonian. [volume]</td>\n",
       "      <td>A.G. Chadwick</td>\n",
       "      <td>https://news-navigator.labs.loc.gov/data/vtu_l...</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath    pub_date  \\\n",
       "0  msar_icydrop_ver05/data/sn83016872/00295878502...  1850-12-31   \n",
       "1  ohi_ingstad_ver01/data/sn85026051/00296027029/...  1850-07-20   \n",
       "2  ohi_ingstad_ver01/data/sn85026051/00296027029/...  1850-08-24   \n",
       "3  ncu_hawk_ver02/data/sn84026472/00416156360/185...  1850-05-22   \n",
       "4  vtu_londonderry_ver01/data/sn84023252/00200296...  1850-03-09   \n",
       "\n",
       "   page_seq_num edition_seq_num                  batch        lccn  \\\n",
       "0           986               1     msar_icydrop_ver05  sn83016872   \n",
       "1            33               1      ohi_ingstad_ver01  sn85026051   \n",
       "2            53               1      ohi_ingstad_ver01  sn85026051   \n",
       "3           289               1         ncu_hawk_ver02  sn84026472   \n",
       "4           247               1  vtu_londonderry_ver01  sn84023252   \n",
       "\n",
       "                                                 box     score  \\\n",
       "0  [0.1624672249571918, 0.026467160391487225, 0.9...  0.963962   \n",
       "1  [0.3009427797781111, 0.6294158908847332, 0.433...  0.929614   \n",
       "2  [0.4334465613731971, 0.6177851558250381, 0.565...  0.979533   \n",
       "3  [0.6732673909317263, 0.042179068056539225, 0.8...  0.914908   \n",
       "4  [0.5134230714407026, 0.1490311215403323, 0.669...  0.922406   \n",
       "\n",
       "                                                 ocr  \\\n",
       "0  [k'.'-vk'', t', :j, 1, !'V1, kkk, .0, :I, .Ii:...   \n",
       "1         [L, -, COME, IN,, WE, CALL, YOU, !, .v';:]   \n",
       "2                        [COME, IN,, WE, CALL, YOU!]   \n",
       "3                                                 []   \n",
       "4                      [OU1, Dr., Jftcob, Townaond.]   \n",
       "\n",
       "             place_of_publication                    geographic_coverage  \\\n",
       "0                   Canton, Miss.         [Mississippi--Madison--Canton]   \n",
       "1  Fremont, Sandusky County, Ohio              [Ohio--Sandusky--Fremont]   \n",
       "2  Fremont, Sandusky County, Ohio              [Ohio--Sandusky--Fremont]   \n",
       "3              Hillsborough, N.C.    [North Carolina--Orange--Hillsboro]   \n",
       "4              St. Johnsbury, Vt.  [Vermont--Caledonia--Saint Johnsbury]   \n",
       "\n",
       "                                  name      publisher  \\\n",
       "0     The Mississippi Creole. [volume]   M.N. Prewett   \n",
       "1     Fremont weekly freeman. [volume]     J.S. Fouke   \n",
       "2     Fremont weekly freeman. [volume]     J.S. Fouke   \n",
       "3  The Hillsborough recorder. [volume]  Dennis Heartt   \n",
       "4             The Caledonian. [volume]  A.G. Chadwick   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://news-navigator.labs.loc.gov/data/msar_...   \n",
       "1  https://news-navigator.labs.loc.gov/data/ohi_i...   \n",
       "2  https://news-navigator.labs.loc.gov/data/ohi_i...   \n",
       "3  https://news-navigator.labs.loc.gov/data/ncu_h...   \n",
       "4  https://news-navigator.labs.loc.gov/data/vtu_l...   \n",
       "\n",
       "                                            page_url  \n",
       "0  https://chroniclingamerica.loc.gov/data/batche...  \n",
       "1  https://chroniclingamerica.loc.gov/data/batche...  \n",
       "2  https://chroniclingamerica.loc.gov/data/batche...  \n",
       "3  https://chroniclingamerica.loc.gov/data/batche...  \n",
       "4  https://chroniclingamerica.loc.gov/data/batche...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sampler.create_sample(sample_size=10, kind='photos', start_year=1850,end_year=1855,reduce_memory=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading a sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 160.74it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 10.51it/s]\n"
     ]
    }
   ],
   "source": [
    "sampler.create_sample(sample_size=10, kind='photos', start_year=1850,end_year=1860,reduce_memory=True)\n",
    "sampler.download_sample('test_iif',pct=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  6.82it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "sampler = nnSampler()\n",
    "sampler.create_sample(1, step=50)\n",
    "sampler.download_sample('test_iif',pct=5)\n",
    "files = [f for f in Path('test_iif').iterdir() if f.suffix == '.jpg']\n",
    "files\n",
    "assert type(Image.open(files[0])) == PIL.JpegImagePlugin.JpegImageFile\n",
    "shutil.rmtree('test_iif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_sample.ipynb.\n",
      "Converted 02_annotate.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnAnnotator",
   "language": "python",
   "name": "nnannotator"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample\n",
    "\n",
    "> Create samples from [Newspaper Navigator](https://news-navigator.labs.loc.gov/) \n",
    "\n",
    "This module allows you to create samples from the newspaper navigator data. If you are only interested in sampling from Newspaper Navigator this is the section you want. \n",
    "\n",
    "The documentation is built from notebooks, so you can open and play with the code in the documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from nnanno.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# TODO tidy imports\n",
    "# sys\n",
    "import io\n",
    "import shutil\n",
    "import pkg_resources\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# other\n",
    "from tqdm.auto import trange, tqdm\n",
    "import requests\n",
    "import ijson\n",
    "import functools\n",
    "import math\n",
    "from cytoolz import dicttoolz, itertoolz\n",
    "import random\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "import itertools\n",
    "from pandas import json_normalize\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from fastcore.foundation import patch_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import PIL\n",
    "from typing import (\n",
    "    Any,\n",
    "    Optional,\n",
    "    Union,\n",
    "    Dict,\n",
    "    List,\n",
    "    Tuple,\n",
    "    Set,\n",
    "    Iterable,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newspaper Navigator JSON files\n",
    "\n",
    "We need to work with the JSON files from the Newspaper Navigator data. The first thing that might be helpful is some code for generating the URLs for a particular year and kind. Since the URLs are systematically structured, this is easy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_json_url(year: Union[str, int], kind: str = \"photos\") -> str:\n",
    "    \"\"\"Returns url for the json data from news-navigator for given `year` and `kind`\"\"\"\n",
    "    return f\"https://news-navigator.labs.loc.gov/prepackaged/{year}_{kind}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    get_json_url(1860)\n",
    "    == \"https://news-navigator.labs.loc.gov/prepackaged/1860_photos.json\"\n",
    ")\n",
    "assert (\n",
    "    get_json_url(1950)\n",
    "    == \"https://news-navigator.labs.loc.gov/prepackaged/1950_photos.json\"\n",
    ")\n",
    "assert (\n",
    "    get_json_url(1950, \"ads\")\n",
    "    == \"https://news-navigator.labs.loc.gov/prepackaged/1950_ads.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def load_json(url: str) -> Dict[str, Any]:\n",
    "    \"\"\"Returns json loaded from `url`\"\"\"\n",
    "    with requests.get(url, timeout=2) as r:\n",
    "        r.raise_for_status()\n",
    "        return json.loads(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also test that this returns what we think inside the notebook. These tests are often hidden in the documentation. However, inside the notebook, there will usually be a cell below a function definition that includes some tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_json = load_json(\n",
    "    \"https://news-navigator.labs.loc.gov/prepackaged/1950_photos.json\"\n",
    ")\n",
    "assert type(test_json[0]) == dict\n",
    "assert type(test_json) == list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with big JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works well for a smallish file but if we try this with the [1905_ads.json](https://news-navigator.labs.loc.gov/prepackaged/1910_ads.json) file which is ~3.3GB we will likely run out of memory. For example running \n",
    "\n",
    "```python\n",
    "with requests.get('https://news-navigator.labs.loc.gov/prepackaged/1910_ads.json') as r:\n",
    "    data = json.loads(r.content)\n",
    "len(data)\n",
    "```\n",
    "\n",
    "on a Google Colab instance with 25GB of RAM causes a crash. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming JSON\n",
    "One way to get around this would be to throw more RAM at the problem. However, since we only want to sample the JSON and don't need to work with the whole dataset, this seems wasteful. So instead, we'll use `ijson`, a Python library for streaming JSON.\n",
    "\n",
    "We can see how this works for a URL from Newspaper Navigator if we create a request via Requests using `stream=True` to return a streaming version of the response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(get_json_url(1850, \"ads\"), stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass this response to `ijson`. In this case we just parse an item at a time. If the JSON is really big this might already be too much. `ijson` allows for much more granular parsing of JSON but for what we need, parsing by item is fine. We can see what the return of this looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_yajl2.items at 0x7fa7204ce030>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects = ijson.items(r.raw, \"item\")\n",
    "objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get back something from `_yajl2` this is the underlying parser `ijson` is using. See `ijson` docs for more on [available parsers](https://pypi.org/project/ijson/#id3). \n",
    "\n",
    "We can call next on this object to start iterating over it, one item at a time. If we look at the keys of the first response, you'll see that this is one entry from the original JSON data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['filepath', 'pub_date', 'page_seq_num', 'edition_seq_num', 'batch', 'lccn', 'box', 'score', 'ocr', 'place_of_publication', 'geographic_coverage', 'name', 'publisher', 'url', 'page_url'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = next(objects)\n",
    "first.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the size of the data \n",
    "\n",
    "If we want to sample from newspaper navigator it is important to be able to know the size of the total population for a given year and kind of image i.e. 10000 photos for 1950. \n",
    "\n",
    "Normally in Python we would use `len` to count the length of a python object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"a\": \"one\", \"b\": \"two\", \"c\": \"three\"}\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try and do this with our `objects` we get an error `TypeError: object of type '_yajl2.items' has no len()`. This is because the point if of ijson is to avoid loading json into memory so we don't know how long the total data will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get around this by using the [toolz](https://toolz.readthedocs.io/en/) libraries [itertoolz.count](https://toolz.readthedocs.io/en/latest/api.html#toolz.itertoolz.count) method. `count` is similar to `len` except that it can work on lazy sequences, i.e. something with a `next` attribute. Unfortunately, this ends up being relatively slow because we still need to go through all of the data, which means that although we can avoid loading the data into memory, we still need to stream it to get the length. We usually won't need to call this repeatedly, but if we call this function multiple times, we cache the results to make sure we don't calculate the length of the same data multiple times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@functools.lru_cache(256)\n",
    "def count_json_iter(url: str, session=None) -> int:\n",
    "    \"\"\"Returns count of objects in url json file using an iterator to avoid loading json into memory\"\"\"\n",
    "    if not session:\n",
    "        session = create_cached_session()\n",
    "    with session.get(url, timeout=60) as r:\n",
    "        r.raise_for_status()\n",
    "        if r:\n",
    "            objects = ijson.items(r.content, \"item\")\n",
    "            count = itertoolz.count(iter(objects))\n",
    "        else:\n",
    "            count = np.nan\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`count_json_iter` counts the length of a json file loaded via `URL`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_json_iter(\"https://news-navigator.labs.loc.gov/prepackaged/1850_photos.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://news-navigator.labs.loc.gov/prepackaged/1850_photos.json\"\n",
    "assert type(count_json_iter(url)) == int\n",
    "assert len(json.loads(requests.get(url).content)) == count_json_iter(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@functools.lru_cache(256)\n",
    "def get_year_size(year: Union[int, str], kind: str) -> dict:\n",
    "    \"\"\"returns size of a json dataset for a given year and kind\n",
    "    results are cached\n",
    "    Parameters\n",
    "    ----------\n",
    "    year : Union[int,str]\n",
    "        year from newspaper navigator\n",
    "    kind : str\n",
    "        {'ads', 'photos', 'maps', 'illustrations', 'comics', 'cartoons', 'headlines'}\n",
    "    Returns\n",
    "    -------\n",
    "    size :dict\n",
    "        returns a dict with year as a key and size as value\n",
    "    \"\"\"\n",
    "    session = None\n",
    "    dset_size = {}\n",
    "    url = get_json_url(year, kind)\n",
    "    if kind == \"ads\" and int(year) >= 1870 or (kind == \"headlines\"):\n",
    "        session = create_session()\n",
    "    dset_size[str(year)] = count_json_iter(url, session)\n",
    "    return dset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1850': 22}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_year_size(1850, \"photos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@functools.lru_cache(512)\n",
    "def get_year_sizes(kind: str, start: int = 1850, end: int = 1950, step: int = 5):\n",
    "    \"\"\"\n",
    "    Returns the sizes for json data files for `kind` between year `start` and `end`\n",
    "    with step size 'step'\n",
    "\n",
    "    Parameters:\n",
    "    kind (str): kind of image from news-navigator:\n",
    "    {'ads', 'photos', 'maps', 'illustrations', 'comics', 'cartoons', 'headlines'}\n",
    "\n",
    "    Returns:\n",
    "    Pandas.DataFrame: holding data from input json url\n",
    "    \"\"\"\n",
    "    futures = []\n",
    "    years = range(start, end + 1, step)\n",
    "    max_workers = get_max_workers(years)\n",
    "    with tqdm(total=len(years)) as progress:\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            for year in years:\n",
    "                future = executor.submit(get_year_size, year, kind)\n",
    "                future.add_done_callback(lambda p: progress.update())\n",
    "                futures.append(future)\n",
    "        results = [future.result() for future in futures]\n",
    "        dset_size = {k: v for d in results for k, v in d.items()}\n",
    "    return pd.DataFrame.from_dict(dset_size, orient=\"index\", columns=[f\"{kind}_count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the year sizes for a given kind, taking a step size `step`. For example, to get the number of photos in the news-navigator dataset between 1850 and 1860 for every year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae76ef27e8d493290da45b2534955f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 146 ms, sys: 37.9 ms, total: 184 ms\n",
      "Wall time: 1.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photos_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      photos_count\n",
       "1850            22\n",
       "1851            20\n",
       "1852            22\n",
       "1853            45\n",
       "1854           221\n",
       "1855            17"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_year_sizes(\"photos\", 1850, 1855, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66987d4a419d46ee978cb4158a7d9d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bc64844a294df0b36c9ef542c71b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert len(get_year_sizes(\"photos\", 1850, 1860, step=1)) == 11\n",
    "assert len(get_year_sizes(\"photos\", 1850, 1860, step=2)) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_all_year_sizes(\n",
    "    start: int = 1850, end: int = 1950, step: int = 1, save: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a dataframe with number of counts from year `start` to `end`\n",
    "    \"\"\"\n",
    "    kinds = [\n",
    "        \"ads\",\n",
    "        \"photos\",\n",
    "        \"maps\",\n",
    "        \"illustrations\",\n",
    "        \"comics\",\n",
    "        \"cartoons\",\n",
    "        \"headlines\",\n",
    "    ]\n",
    "    dfs = []\n",
    "    for kind in tqdm(kinds):\n",
    "        df = get_year_sizes(kind, start=start, end=end, step=step)\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs, axis=1)\n",
    "    df[\"total\"] = df.sum(axis=1)\n",
    "    if save:\n",
    "        df.to_csv(\"all_year_sizes.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming sampling\n",
    "\n",
    "Since we want a subset of the Newspaper Navigator datasets we can either work with for annotation or inference, we want to create samples. Sampling in Python can be complicated depending on the type of population you are working with and your sample's properties. Usually, we can do something relatively simple. For example, if we want to sample from a selection of books, we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['War and Peace']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "books = [\"War and Peace\", \"Frankenstein\", \"If They Come in the Morning\"]\n",
    "random.sample(books, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we run into the same problem as trying to get the length of a JSON dataset that wouldn't fit into memory above. For example, we want to sample $k$ examples from one of our JSON files that we can't load into memory. To get around this, we can use [Reservoir_sampling](https://en.wikipedia.org/wiki/Reservoir_sampling):\n",
    "\n",
    "> Reservoir sampling is a family of randomized algorithms for choosing a simple random sample without replacement of k items from a population of unknown size n in a single pass over the items. The size of the population n is not known to the algorithm and is typically too large to fit all n items into main memory. The population is revealed to the algorithm over time, and the algorithm cannot look back at previous items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def sample_stream(stream, k: int):\n",
    "    \"\"\"\n",
    "    Return a random sample of k elements drawn without replacement from stream.\n",
    "    Designed to be used when the elements of stream cannot easily fit into memory.\n",
    "    \"\"\"\n",
    "    r = np.array(list(itertools.islice(stream, k)))\n",
    "    for t, x in enumerate(stream, k + 1):\n",
    "        i = np.random.randint(1, t + 1)\n",
    "        if i <= k:\n",
    "            r[i - 1] = x\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we sample whilst only loading a small number of items into memory at one time. This does come at some cost, mainly speed. There are faster ways of sampling from a stream but this isn't the main bottle neck for sampling in this case. We can for example sample from a large range of numbers without memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([62151, 45070, 43590, 71352, 61951])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_stream(range(1, 100000), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still sample from lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Karl Marx', 'Raya Dunayevsk'], dtype='<U14')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [\"Karl Marx\", \"Rosa Luxenburg\", \"Raya Dunayevskaya\", \"CLR James\"]\n",
    "sample_stream(iter(names), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "assert len(sample_stream(range(1, 100), 5)) == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@functools.lru_cache(1024)\n",
    "def calc_frac_size(url, frac, session=None):\n",
    "    \"returns fraction size from a json stream\"\n",
    "    return round(count_json_iter(url, session) * frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "url = get_json_url(1850)\n",
    "assert calc_frac_size(url, 0.5) == 11  # 22*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def calc_year_from_total(total, start, end, step):\n",
    "    \"Calculate size of a year sample based on a total sample size\"\n",
    "    return max(1, round(total / (((end - start) + 1) / step)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_year_from_total(10, 1850, 18950, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "assert (\n",
    "    calc_year_from_total(10, 1850, 1950, 1) >= 1\n",
    ")  # test that a value is always returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing memory usage\n",
    "\n",
    "Since we are trying to be a bit careful with memory usage we will convert column `dtypes` to be smaller when possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def reduce_df_memory(df):\n",
    "    return df.astype(\n",
    "        {\n",
    "            \"score\": \"float64\",\n",
    "            \"page_seq_num\": \"int32\",\n",
    "            \"batch\": \"category\",\n",
    "            \"box\": \"object\",\n",
    "            \"lccn\": \"category\",\n",
    "            \"page_url\": \"category\",\n",
    "            \"name\": \"category\",\n",
    "            \"publisher\": \"category\",\n",
    "            \"place_of_publication\": \"category\",\n",
    "            \"edition_seq_num\": \"category\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Newspaper navigator \n",
    "\n",
    "We now start building up a class `nnSampler` for doing our proper sampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class nnSampler:\n",
    "    \"\"\"Sampler for creating samples from Newspaper Navigator data\"\"\"\n",
    "\n",
    "    population = pd.read_csv(\n",
    "        pkg_resources.resource_stream(\"nnanno\", \"data/all_year_counts.csv\"), index_col=0\n",
    "    )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"nnSampler\" class=\"doc_header\"><code>class</code> <code>nnSampler</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>nnSampler</code>()\n",
       "\n",
       "Sampler for creating samples from Newspaper Navigator data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(nnSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def sample_year(kind: str, sample_size: Union[int, float], year: int) -> np.array:\n",
    "    \"\"\"samples `sample_size` for `year` and `kind`\"\"\"\n",
    "    url = get_json_url(year, kind)\n",
    "    if kind == \"ads\" and int(year) >= 1870 or (kind == \"headlines\"):\n",
    "        session = create_session()\n",
    "    else:\n",
    "        session = create_cached_session()\n",
    "    if type(sample_size) is float:\n",
    "        sample_size = max(1, calc_frac_size(url, sample_size, session))\n",
    "        if kind == \"ads\" and int(year) >= 1870 or (kind == \"headlines\"):\n",
    "            session = create_session()\n",
    "        else:\n",
    "            session = create_cached_session()\n",
    "    with session.get(get_json_url(year, kind)) as r:\n",
    "        if r:\n",
    "            try:\n",
    "                data = ijson.items(r.content, \"item\")\n",
    "                sample_data = sample_stream(iter(data), sample_size)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                sample_data = np.nan\n",
    "        return sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"sample_year\" class=\"doc_header\"><code>sample_year</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>sample_year</code>(**`kind`**:`str`, **`sample_size`**:`Union`\\[`int`, `float`\\], **`year`**:`int`)\n",
       "\n",
       "samples `sample_size` for `year` and `kind`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(sample_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_year(\"photos\", 1, 1850)\n",
    "assert (\n",
    "    len(sample_year(\"maps\", 0.1, 1850)) == 1\n",
    ")  # test we always have a sample size of at least one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch_to(nnSampler)\n",
    "def create_sample(\n",
    "    self,\n",
    "    sample_size: Union[int, float],\n",
    "    kind: str = \"photos\",\n",
    "    start_year: int = 1850,\n",
    "    end_year: int = 1950,\n",
    "    step: int = 5,\n",
    "    year_sample=True,\n",
    "    save: bool = False,\n",
    "    reduce_memory=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a sample of Newspaper Navigator data for a given set of years and a kind\n",
    "\n",
    "    Parameters:\n",
    "    sample_size: int, float\n",
    "        `sample size` can either be a fixed number or a fraction of the total dataset size\n",
    "    kind (str): kind of image from news-navigator:\n",
    "    {'ads', 'photos', 'maps', 'illustrations', 'comics', 'cartoons', 'headlines'}\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    Pandas.DataFrame: holding data from input json url\n",
    "    \"\"\"\n",
    "\n",
    "    if not year_sample:\n",
    "        if type(sample_size) != int:\n",
    "            raise ValueError(\n",
    "                f\"\"\"type{sample_size} is not an int. Fractions are only supported\n",
    "                            for sampling by year\"\"\"\n",
    "            )\n",
    "        sample_size = calc_year_from_total(sample_size, start_year, end_year, step)\n",
    "    futures = []\n",
    "    years = range(start_year, end_year + 1, step)\n",
    "    _year_sample = partial(sample_year, kind, sample_size)\n",
    "    with tqdm(total=len(years)) as progress:\n",
    "        workers = get_max_workers(years)\n",
    "        with concurrent.futures.ThreadPoolExecutor(1) as executor:\n",
    "            for year in years:\n",
    "                future = executor.submit(_year_sample, year)\n",
    "                future.add_done_callback(lambda p: progress.update())\n",
    "                futures.append(future)\n",
    "    results = [future.result() for future in futures]\n",
    "    df = pd.DataFrame.from_dict(list(itertoolz.concat(results)))\n",
    "\n",
    "    if reduce_memory:\n",
    "        df = reduce_df_memory(df)\n",
    "    if save:\n",
    "        df.to_json(f\"{kind}_{start_year}_{end_year}_sample.json\")\n",
    "    self.sample = df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"nnSampler.create_sample\" class=\"doc_header\"><code>nnSampler.create_sample</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>nnSampler.create_sample</code>(**`sample_size`**:`Union`\\[`int`, `float`\\], **`kind`**:`str`=*`'photos'`*, **`start_year`**:`int`=*`1850`*, **`end_year`**:`int`=*`1950`*, **`step`**:`int`=*`5`*, **`year_sample`**=*`True`*, **`save`**:`bool`=*`False`*, **`reduce_memory`**=*`True`*)\n",
       "\n",
       "Creates a sample of Newspaper Navigator data for a given set of years and a kind\n",
       "\n",
       "Parameters:\n",
       "sample_size: int, float\n",
       "    `sample size` can either be a fixed number or a fraction of the total dataset size\n",
       "kind (str): kind of image from news-navigator:\n",
       "{'ads', 'photos', 'maps', 'illustrations', 'comics', 'cartoons', 'headlines'}\n",
       "\n",
       "\n",
       "Returns:\n",
       "Pandas.DataFrame: holding data from input json url"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(nnSampler.create_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_sample` returns a dataframe which samples from Newspaper Navigator. `year_sample` controls whether you want `sample_size` to be for each year or for you entire sample. Selecting `year_sample` false will return a sample of a size close to what you define in `sample_size`. This is useful for example if you plan to annotate your sample with some new labels.\n",
    "\n",
    "For any years where sample size is larger than the sample available you just get everything for that year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39458f7afd844b4db008a7f0e1fb92e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>page_seq_num</th>\n",
       "      <th>edition_seq_num</th>\n",
       "      <th>batch</th>\n",
       "      <th>lccn</th>\n",
       "      <th>box</th>\n",
       "      <th>score</th>\n",
       "      <th>ocr</th>\n",
       "      <th>place_of_publication</th>\n",
       "      <th>geographic_coverage</th>\n",
       "      <th>name</th>\n",
       "      <th>publisher</th>\n",
       "      <th>url</th>\n",
       "      <th>page_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>msar_icydrop_ver05/data/sn86074079/00295878502...</td>\n",
       "      <td>1850-12-05</td>\n",
       "      <td>1149</td>\n",
       "      <td>1</td>\n",
       "      <td>msar_icydrop_ver05</td>\n",
       "      <td>sn86074079</td>\n",
       "      <td>[0.4527419749698691, 0.07917078993055555, 0.75...</td>\n",
       "      <td>0.951330</td>\n",
       "      <td>[Wednesday, Dec., Uth, one, day, only., -, i, ...</td>\n",
       "      <td>Canton, Miss.</td>\n",
       "      <td>[Mississippi--Madison--Canton]</td>\n",
       "      <td>The Madisonian.</td>\n",
       "      <td>R.D. Price</td>\n",
       "      <td>https://news-navigator.labs.loc.gov/data/msar_...</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in_indianapolisolympians_ver02/data/sn86058217...</td>\n",
       "      <td>1850-04-03</td>\n",
       "      <td>470</td>\n",
       "      <td>1</td>\n",
       "      <td>in_indianapolisolympians_ver02</td>\n",
       "      <td>sn86058217</td>\n",
       "      <td>[0.19613312344418035, 0.41648075810185187, 0.3...</td>\n",
       "      <td>0.943215</td>\n",
       "      <td>[,, j, ii, i:, 1., 1, a, it, A, I, II, V, ...]</td>\n",
       "      <td>Richmond, IA [i.e. Ind.]</td>\n",
       "      <td>[Indiana--Wayne--Richmond]</td>\n",
       "      <td>Richmond palladium. [volume]</td>\n",
       "      <td>D.P. Holloway &amp; B.W. Davis</td>\n",
       "      <td>https://news-navigator.labs.loc.gov/data/in_in...</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ohi_ingstad_ver01/data/sn85026051/00296027029/...</td>\n",
       "      <td>1850-12-07</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>ohi_ingstad_ver01</td>\n",
       "      <td>sn85026051</td>\n",
       "      <td>[0.30707743987524494, 0.6473851770787806, 0.44...</td>\n",
       "      <td>0.984739</td>\n",
       "      <td>[COME, IN,, WE, CALL, YOU!]</td>\n",
       "      <td>Fremont, Sandusky County, Ohio</td>\n",
       "      <td>[Ohio--Sandusky--Fremont]</td>\n",
       "      <td>Fremont weekly freeman. [volume]</td>\n",
       "      <td>J.S. Fouke</td>\n",
       "      <td>https://news-navigator.labs.loc.gov/data/ohi_i...</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ohi_edgar_ver01/data/sn85038121/00280775502/18...</td>\n",
       "      <td>1852-06-24</td>\n",
       "      <td>443</td>\n",
       "      <td>1</td>\n",
       "      <td>ohi_edgar_ver01</td>\n",
       "      <td>sn85038121</td>\n",
       "      <td>[0.5482568719219458, 0.05572789142773935, 0.80...</td>\n",
       "      <td>0.966192</td>\n",
       "      <td>[;, 'Y, '., \", i, ', -, 7, i, ', f, 1,, ft, ',...</td>\n",
       "      <td>Gallipolis, Ohio</td>\n",
       "      <td>[Ohio--Gallia--Gallipolis]</td>\n",
       "      <td>Gallipolis journal. [volume]</td>\n",
       "      <td>Alexander Vance</td>\n",
       "      <td>https://news-navigator.labs.loc.gov/data/ohi_e...</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>msar_cloudchaser_ver01/data/sn87065038/0029587...</td>\n",
       "      <td>1852-10-07</td>\n",
       "      <td>262</td>\n",
       "      <td>1</td>\n",
       "      <td>msar_cloudchaser_ver01</td>\n",
       "      <td>sn87065038</td>\n",
       "      <td>[0.4655820986278216, 0.5739247633736971, 0.601...</td>\n",
       "      <td>0.968907</td>\n",
       "      <td>[i, \"ntnTf-fhr-i, -irrr-T-, r, ., -, J, I]</td>\n",
       "      <td>Columbus, Miss.</td>\n",
       "      <td>[Mississippi--Lowndes--Columbus]</td>\n",
       "      <td>The primitive Republican.</td>\n",
       "      <td>F.G. Baldwin</td>\n",
       "      <td>https://news-navigator.labs.loc.gov/data/msar_...</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>txdn_eastland_ver01/data/sn83025730/0027955983...</td>\n",
       "      <td>1852-07-10</td>\n",
       "      <td>611</td>\n",
       "      <td>1</td>\n",
       "      <td>txdn_eastland_ver01</td>\n",
       "      <td>sn83025730</td>\n",
       "      <td>[0.6132026808043348, 0.2620943737307529, 0.975...</td>\n",
       "      <td>0.982666</td>\n",
       "      <td>[1, i, ||, «, -, ', #, •«, ft,, %, &gt;*&lt;», I, &lt;,...</td>\n",
       "      <td>Marshall, Tex.</td>\n",
       "      <td>[Texas--Harrison--Marshall]</td>\n",
       "      <td>The Texas Republican. [volume]</td>\n",
       "      <td>F.J. Patillo</td>\n",
       "      <td>https://news-navigator.labs.loc.gov/data/txdn_...</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath    pub_date  \\\n",
       "0  msar_icydrop_ver05/data/sn86074079/00295878502...  1850-12-05   \n",
       "1  in_indianapolisolympians_ver02/data/sn86058217...  1850-04-03   \n",
       "2  ohi_ingstad_ver01/data/sn85026051/00296027029/...  1850-12-07   \n",
       "3  ohi_edgar_ver01/data/sn85038121/00280775502/18...  1852-06-24   \n",
       "4  msar_cloudchaser_ver01/data/sn87065038/0029587...  1852-10-07   \n",
       "5  txdn_eastland_ver01/data/sn83025730/0027955983...  1852-07-10   \n",
       "\n",
       "   page_seq_num edition_seq_num                           batch        lccn  \\\n",
       "0          1149               1              msar_icydrop_ver05  sn86074079   \n",
       "1           470               1  in_indianapolisolympians_ver02  sn86058217   \n",
       "2           115               1               ohi_ingstad_ver01  sn85026051   \n",
       "3           443               1                 ohi_edgar_ver01  sn85038121   \n",
       "4           262               1          msar_cloudchaser_ver01  sn87065038   \n",
       "5           611               1             txdn_eastland_ver01  sn83025730   \n",
       "\n",
       "                                                 box     score  \\\n",
       "0  [0.4527419749698691, 0.07917078993055555, 0.75...  0.951330   \n",
       "1  [0.19613312344418035, 0.41648075810185187, 0.3...  0.943215   \n",
       "2  [0.30707743987524494, 0.6473851770787806, 0.44...  0.984739   \n",
       "3  [0.5482568719219458, 0.05572789142773935, 0.80...  0.966192   \n",
       "4  [0.4655820986278216, 0.5739247633736971, 0.601...  0.968907   \n",
       "5  [0.6132026808043348, 0.2620943737307529, 0.975...  0.982666   \n",
       "\n",
       "                                                 ocr  \\\n",
       "0  [Wednesday, Dec., Uth, one, day, only., -, i, ...   \n",
       "1     [,, j, ii, i:, 1., 1, a, it, A, I, II, V, ...]   \n",
       "2                        [COME, IN,, WE, CALL, YOU!]   \n",
       "3  [;, 'Y, '., \", i, ', -, 7, i, ', f, 1,, ft, ',...   \n",
       "4         [i, \"ntnTf-fhr-i, -irrr-T-, r, ., -, J, I]   \n",
       "5  [1, i, ||, «, -, ', #, •«, ft,, %, >*<», I, <,...   \n",
       "\n",
       "             place_of_publication               geographic_coverage  \\\n",
       "0                   Canton, Miss.    [Mississippi--Madison--Canton]   \n",
       "1        Richmond, IA [i.e. Ind.]        [Indiana--Wayne--Richmond]   \n",
       "2  Fremont, Sandusky County, Ohio         [Ohio--Sandusky--Fremont]   \n",
       "3                Gallipolis, Ohio        [Ohio--Gallia--Gallipolis]   \n",
       "4                 Columbus, Miss.  [Mississippi--Lowndes--Columbus]   \n",
       "5                  Marshall, Tex.       [Texas--Harrison--Marshall]   \n",
       "\n",
       "                               name                   publisher  \\\n",
       "0                   The Madisonian.                  R.D. Price   \n",
       "1      Richmond palladium. [volume]  D.P. Holloway & B.W. Davis   \n",
       "2  Fremont weekly freeman. [volume]                  J.S. Fouke   \n",
       "3      Gallipolis journal. [volume]             Alexander Vance   \n",
       "4         The primitive Republican.                F.G. Baldwin   \n",
       "5    The Texas Republican. [volume]                F.J. Patillo   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://news-navigator.labs.loc.gov/data/msar_...   \n",
       "1  https://news-navigator.labs.loc.gov/data/in_in...   \n",
       "2  https://news-navigator.labs.loc.gov/data/ohi_i...   \n",
       "3  https://news-navigator.labs.loc.gov/data/ohi_e...   \n",
       "4  https://news-navigator.labs.loc.gov/data/msar_...   \n",
       "5  https://news-navigator.labs.loc.gov/data/txdn_...   \n",
       "\n",
       "                                            page_url  \n",
       "0  https://chroniclingamerica.loc.gov/data/batche...  \n",
       "1  https://chroniclingamerica.loc.gov/data/batche...  \n",
       "2  https://chroniclingamerica.loc.gov/data/batche...  \n",
       "3  https://chroniclingamerica.loc.gov/data/batche...  \n",
       "4  https://chroniclingamerica.loc.gov/data/batche...  \n",
       "5  https://chroniclingamerica.loc.gov/data/batche...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = nnSampler()\n",
    "sampler.create_sample(5, step=2, end_year=1852, year_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch_to(nnSampler)\n",
    "def download_sample(\n",
    "    self,\n",
    "    out_dir: str,\n",
    "    json_name: Optional[str] = None,\n",
    "    df: Optional[pd.DataFrame] = None,\n",
    "    original: bool = True,\n",
    "    pct: Optional[int] = None,\n",
    "    size: Optional[tuple] = None,\n",
    "    preserve_asp_ratio: bool = True,\n",
    ") -> Union[None]:\n",
    "    \"\"\"Download images associated with a sample\n",
    "    The majority of paramters relate to the options available in a IIIF image request\n",
    "    see `https://iiif.io/api/image/3.0/#4-image-requests` for further information\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    out_dir\n",
    "        The save directory for the images\n",
    "    json_name\n",
    "\n",
    "    df\n",
    "        optional DataFrame containing a sample\n",
    "    original\n",
    "        if `True` will download orginal size images via IIIF\n",
    "    pct\n",
    "        optional value which scales the size of images requested by `pct`\n",
    "    size\n",
    "        a tuple representing `width` by `height`, will be passed to IIIF request\n",
    "    preserve_asp_ratio\n",
    "        whether to ask the IIIF request to preserve aspect ratio of image or not\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    if df is not None:\n",
    "        self.download_df = df.copy(deep=True)\n",
    "    else:\n",
    "        try:\n",
    "            self.download_df = self.sample.copy(deep=True)\n",
    "        except AttributeError as E:\n",
    "            print(\n",
    "                \"You need to create a sample before downloading, or pass in a previously created \"\n",
    "            )\n",
    "    self.download_df[\"iiif_url\"] = self.download_df.apply(\n",
    "        lambda x: iiif_df_apply(\n",
    "            x,\n",
    "            original=original,\n",
    "            pct=pct,\n",
    "            size=size,\n",
    "            preserve_asp_ratio=preserve_asp_ratio,\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    self.download_df[\"download_image_path\"] = self.download_df[\"filepath\"].str.replace(\n",
    "        \"/\", \"_\"\n",
    "    )\n",
    "\n",
    "    if not Path(out_dir).exists():\n",
    "        Path(out_dir).mkdir(parents=True)\n",
    "    _download_image = lambda x: download_image(\n",
    "        x.iiif_url, x.download_image_path, out_dir\n",
    "    )\n",
    "    with tqdm(total=len(self.download_df)) as progress:\n",
    "        workers = get_max_workers(self.download_df)\n",
    "        with concurrent.futures.ThreadPoolExecutor(workers) as executor:\n",
    "            futures = []\n",
    "            for tuple_row in self.download_df.itertuples():\n",
    "                future = executor.submit(_download_image, tuple_row)\n",
    "                future.add_done_callback(lambda p: progress.update())\n",
    "                futures.append(future)\n",
    "            del futures\n",
    "    if json_name is None:\n",
    "        today = datetime.today()\n",
    "        time_stamp = today.strftime(\"%Y_%d_%m_%H_%M\")\n",
    "        json_name = f\"{time_stamp}_{len(self.download_df)}_sample\"\n",
    "    self.download_df.to_json(f\"{out_dir}/{json_name}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"nnSampler.download_sample\" class=\"doc_header\"><code>nnSampler.download_sample</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>nnSampler.download_sample</code>(**`out_dir`**:`str`, **`json_name`**:`Optional`\\[`str`\\]=*`None`*, **`df`**:`Optional`\\[`DataFrame`\\]=*`None`*, **`original`**:`bool`=*`True`*, **`pct`**:`Optional`\\[`int`\\]=*`None`*, **`size`**:`Optional`\\[`tuple`\\]=*`None`*, **`preserve_asp_ratio`**:`bool`=*`True`*)\n",
       "\n",
       "Download images associated with a sample\n",
       "The majority of paramters relate to the options available in a IIIF image request\n",
       "see `https://iiif.io/api/image/3.0/#4-image-requests` for further information\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "out_dir\n",
       "    The save directory for the images\n",
       "json_name\n",
       "\n",
       "df\n",
       "    optional DataFrame containing a sample\n",
       "original\n",
       "    if `True` will download orginal size images via IIIF\n",
       "pct\n",
       "    optional value which scales the size of images requested by `pct`\n",
       "size\n",
       "    a tuple representing `width` by `height`, will be passed to IIIF request\n",
       "preserve_asp_ratio\n",
       "    whether to ask the IIIF request to preserve aspect ratio of image or not\n",
       "\n",
       "Returns\n",
       "-------\n",
       "None"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(nnSampler.download_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`download_sample` is used to download images from a `sample`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = nnSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnSampler"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ads_count</th>\n",
       "      <th>photos_count</th>\n",
       "      <th>maps_count</th>\n",
       "      <th>illustrations_count</th>\n",
       "      <th>comics_count</th>\n",
       "      <th>cartoons_count</th>\n",
       "      <th>headlines_count</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>8841</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>671</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>11243</td>\n",
       "      <td>20791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>10065</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>457</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>12262</td>\n",
       "      <td>22817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>8764</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>671</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>13524</td>\n",
       "      <td>23009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>11517</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>1106</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>13224</td>\n",
       "      <td>25986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>15050</td>\n",
       "      <td>221</td>\n",
       "      <td>15</td>\n",
       "      <td>732</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>15282</td>\n",
       "      <td>31314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>185139</td>\n",
       "      <td>5945</td>\n",
       "      <td>1857</td>\n",
       "      <td>1053</td>\n",
       "      <td>3280</td>\n",
       "      <td>861</td>\n",
       "      <td>68275</td>\n",
       "      <td>266410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>181223</td>\n",
       "      <td>4188</td>\n",
       "      <td>1750</td>\n",
       "      <td>1115</td>\n",
       "      <td>3630</td>\n",
       "      <td>797</td>\n",
       "      <td>57018</td>\n",
       "      <td>249721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>152987</td>\n",
       "      <td>4282</td>\n",
       "      <td>1359</td>\n",
       "      <td>1154</td>\n",
       "      <td>3031</td>\n",
       "      <td>624</td>\n",
       "      <td>43432</td>\n",
       "      <td>206869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>154510</td>\n",
       "      <td>6015</td>\n",
       "      <td>1888</td>\n",
       "      <td>1280</td>\n",
       "      <td>3356</td>\n",
       "      <td>634</td>\n",
       "      <td>42904</td>\n",
       "      <td>210587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>154961</td>\n",
       "      <td>5630</td>\n",
       "      <td>1952</td>\n",
       "      <td>1223</td>\n",
       "      <td>3893</td>\n",
       "      <td>704</td>\n",
       "      <td>37854</td>\n",
       "      <td>206217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ads_count  photos_count  maps_count  illustrations_count  comics_count  \\\n",
       "1850       8841            22           5                  671             9   \n",
       "1851      10065            20           6                  457             7   \n",
       "1852       8764            22          10                  671            10   \n",
       "1853      11517            45           5                 1106            88   \n",
       "1854      15050           221          15                  732            11   \n",
       "...         ...           ...         ...                  ...           ...   \n",
       "1946     185139          5945        1857                 1053          3280   \n",
       "1947     181223          4188        1750                 1115          3630   \n",
       "1948     152987          4282        1359                 1154          3031   \n",
       "1949     154510          6015        1888                 1280          3356   \n",
       "1950     154961          5630        1952                 1223          3893   \n",
       "\n",
       "      cartoons_count  headlines_count   total  \n",
       "1850               0            11243   20791  \n",
       "1851               0            12262   22817  \n",
       "1852               8            13524   23009  \n",
       "1853               1            13224   25986  \n",
       "1854               3            15282   31314  \n",
       "...              ...              ...     ...  \n",
       "1946             861            68275  266410  \n",
       "1947             797            57018  249721  \n",
       "1948             624            43432  206869  \n",
       "1949             634            42904  210587  \n",
       "1950             704            37854  206217  \n",
       "\n",
       "[101 rows x 8 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler.population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbf638c48354303acc2ce68056c2d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>page_seq_num</th>\n",
       "      <th>edition_seq_num</th>\n",
       "      <th>batch</th>\n",
       "      <th>lccn</th>\n",
       "      <th>box</th>\n",
       "      <th>score</th>\n",
       "      <th>ocr</th>\n",
       "      <th>place_of_publication</th>\n",
       "      <th>geographic_coverage</th>\n",
       "      <th>name</th>\n",
       "      <th>publisher</th>\n",
       "      <th>url</th>\n",
       "      <th>page_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ohi_ingstad_ver01/data/sn85026051/00296027029/...</td>\n",
       "      <td>1850-07-27</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>ohi_ingstad_ver01</td>\n",
       "      <td>sn85026051</td>\n",
       "      <td>[0.29913574490319106, 0.622813938380955, 0.430...</td>\n",
       "      <td>0.980025</td>\n",
       "      <td>[ht, I, ', Wll., ., III, tl, T, ., \"', \"', \", ...</td>\n",
       "      <td>Fremont, Sandusky County, Ohio</td>\n",
       "      <td>[Ohio--Sandusky--Fremont]</td>\n",
       "      <td>Fremont weekly freeman. [volume]</td>\n",
       "      <td>J.S. Fouke</td>\n",
       "      <td>https://news-navigator.labs.loc.gov/data/ohi_i...</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ohi_ingstad_ver01/data/sn85026051/00296027029/...</td>\n",
       "      <td>1850-07-20</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>ohi_ingstad_ver01</td>\n",
       "      <td>sn85026051</td>\n",
       "      <td>[0.3009427797781111, 0.6294158908847332, 0.433...</td>\n",
       "      <td>0.929614</td>\n",
       "      <td>[L, -, COME, IN,, WE, CALL, YOU, !, .v';:]</td>\n",
       "      <td>Fremont, Sandusky County, Ohio</td>\n",
       "      <td>[Ohio--Sandusky--Fremont]</td>\n",
       "      <td>Fremont weekly freeman. [volume]</td>\n",
       "      <td>J.S. Fouke</td>\n",
       "      <td>https://news-navigator.labs.loc.gov/data/ohi_i...</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ncu_hawk_ver02/data/sn84026472/00416156360/185...</td>\n",
       "      <td>1850-05-22</td>\n",
       "      <td>289</td>\n",
       "      <td>1</td>\n",
       "      <td>ncu_hawk_ver02</td>\n",
       "      <td>sn84026472</td>\n",
       "      <td>[0.6732673909317263, 0.042179068056539225, 0.8...</td>\n",
       "      <td>0.914908</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hillsborough, N.C.</td>\n",
       "      <td>[North Carolina--Orange--Hillsboro]</td>\n",
       "      <td>The Hillsborough recorder. [volume]</td>\n",
       "      <td>Dennis Heartt</td>\n",
       "      <td>https://news-navigator.labs.loc.gov/data/ncu_h...</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>msar_icydrop_ver05/data/sn86074079/00295878502...</td>\n",
       "      <td>1850-12-05</td>\n",
       "      <td>1149</td>\n",
       "      <td>1</td>\n",
       "      <td>msar_icydrop_ver05</td>\n",
       "      <td>sn86074079</td>\n",
       "      <td>[0.4527419749698691, 0.07917078993055555, 0.75...</td>\n",
       "      <td>0.951330</td>\n",
       "      <td>[Wednesday, Dec., Uth, one, day, only., -, i, ...</td>\n",
       "      <td>Canton, Miss.</td>\n",
       "      <td>[Mississippi--Madison--Canton]</td>\n",
       "      <td>The Madisonian.</td>\n",
       "      <td>R.D. Price</td>\n",
       "      <td>https://news-navigator.labs.loc.gov/data/msar_...</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vtu_londonderry_ver01/data/sn84023252/00200296...</td>\n",
       "      <td>1850-05-11</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>vtu_londonderry_ver01</td>\n",
       "      <td>sn84023252</td>\n",
       "      <td>[0.5275910554108796, 0.16344128086556137, 0.68...</td>\n",
       "      <td>0.915448</td>\n",
       "      <td>[Old, Dr., Jnaob, TownHond,, 'Jlu, Utigiml, l)...</td>\n",
       "      <td>St. Johnsbury, Vt.</td>\n",
       "      <td>[Vermont--Caledonia--Saint Johnsbury]</td>\n",
       "      <td>The Caledonian. [volume]</td>\n",
       "      <td>A.G. Chadwick</td>\n",
       "      <td>https://news-navigator.labs.loc.gov/data/vtu_l...</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath    pub_date  \\\n",
       "0  ohi_ingstad_ver01/data/sn85026051/00296027029/...  1850-07-27   \n",
       "1  ohi_ingstad_ver01/data/sn85026051/00296027029/...  1850-07-20   \n",
       "2  ncu_hawk_ver02/data/sn84026472/00416156360/185...  1850-05-22   \n",
       "3  msar_icydrop_ver05/data/sn86074079/00295878502...  1850-12-05   \n",
       "4  vtu_londonderry_ver01/data/sn84023252/00200296...  1850-05-11   \n",
       "\n",
       "   page_seq_num edition_seq_num                  batch        lccn  \\\n",
       "0            37               1      ohi_ingstad_ver01  sn85026051   \n",
       "1            33               1      ohi_ingstad_ver01  sn85026051   \n",
       "2           289               1         ncu_hawk_ver02  sn84026472   \n",
       "3          1149               1     msar_icydrop_ver05  sn86074079   \n",
       "4           283               1  vtu_londonderry_ver01  sn84023252   \n",
       "\n",
       "                                                 box     score  \\\n",
       "0  [0.29913574490319106, 0.622813938380955, 0.430...  0.980025   \n",
       "1  [0.3009427797781111, 0.6294158908847332, 0.433...  0.929614   \n",
       "2  [0.6732673909317263, 0.042179068056539225, 0.8...  0.914908   \n",
       "3  [0.4527419749698691, 0.07917078993055555, 0.75...  0.951330   \n",
       "4  [0.5275910554108796, 0.16344128086556137, 0.68...  0.915448   \n",
       "\n",
       "                                                 ocr  \\\n",
       "0  [ht, I, ', Wll., ., III, tl, T, ., \"', \"', \", ...   \n",
       "1         [L, -, COME, IN,, WE, CALL, YOU, !, .v';:]   \n",
       "2                                                 []   \n",
       "3  [Wednesday, Dec., Uth, one, day, only., -, i, ...   \n",
       "4  [Old, Dr., Jnaob, TownHond,, 'Jlu, Utigiml, l)...   \n",
       "\n",
       "             place_of_publication                    geographic_coverage  \\\n",
       "0  Fremont, Sandusky County, Ohio              [Ohio--Sandusky--Fremont]   \n",
       "1  Fremont, Sandusky County, Ohio              [Ohio--Sandusky--Fremont]   \n",
       "2              Hillsborough, N.C.    [North Carolina--Orange--Hillsboro]   \n",
       "3                   Canton, Miss.         [Mississippi--Madison--Canton]   \n",
       "4              St. Johnsbury, Vt.  [Vermont--Caledonia--Saint Johnsbury]   \n",
       "\n",
       "                                  name      publisher  \\\n",
       "0     Fremont weekly freeman. [volume]     J.S. Fouke   \n",
       "1     Fremont weekly freeman. [volume]     J.S. Fouke   \n",
       "2  The Hillsborough recorder. [volume]  Dennis Heartt   \n",
       "3                      The Madisonian.     R.D. Price   \n",
       "4             The Caledonian. [volume]  A.G. Chadwick   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://news-navigator.labs.loc.gov/data/ohi_i...   \n",
       "1  https://news-navigator.labs.loc.gov/data/ohi_i...   \n",
       "2  https://news-navigator.labs.loc.gov/data/ncu_h...   \n",
       "3  https://news-navigator.labs.loc.gov/data/msar_...   \n",
       "4  https://news-navigator.labs.loc.gov/data/vtu_l...   \n",
       "\n",
       "                                            page_url  \n",
       "0  https://chroniclingamerica.loc.gov/data/batche...  \n",
       "1  https://chroniclingamerica.loc.gov/data/batche...  \n",
       "2  https://chroniclingamerica.loc.gov/data/batche...  \n",
       "3  https://chroniclingamerica.loc.gov/data/batche...  \n",
       "4  https://chroniclingamerica.loc.gov/data/batche...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sampler.create_sample(\n",
    "    sample_size=10, kind=\"photos\", start_year=1850, end_year=1855, reduce_memory=True\n",
    ")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading a sample \n",
    "We may want to work with images locally. We can download them using the `download_sample` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41afa6eba9944f3099c5f09b014b9d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1bfa2eef2942938648d60750d75569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampler.create_sample(\n",
    "    sample_size=10, kind=\"ads\", start_year=1850, end_year=1850, reduce_memory=True\n",
    ")\n",
    "sampler.download_sample(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "files = [f for f in Path(\"test/\").iterdir()]\n",
    "json_file = list(Path(\"test\").glob(\"*.json\"))\n",
    "df = pd.read_json(json_file[0])\n",
    "assert len(df) == 10\n",
    "# check iiif urls from df return at least some images\n",
    "iiif_url_load_results = map(load_url_image, df[\"iiif_url\"])\n",
    "assert any(type(result) == PIL.Image.Image for result in iiif_url_load_results) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# tidyup\n",
    "files = [f for f in Path(\"test/\").iterdir()]\n",
    "list(map(Path.unlink, files))\n",
    "Path(\"test\").rmdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_sample.ipynb.\n",
      "Converted 02_annotate.ipynb.\n",
      "Converted 03_inference.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

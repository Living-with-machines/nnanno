{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp annotate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate\n",
    "\n",
    "> Functionality to support creating and process annotation for samples of Newspaper Navigator data using Label Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import rapidjson as json\n",
    "import requests\n",
    "import re\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import rapidjson as json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup annotation task\n",
    "The bulk of annotation work is outsourced to labelstudio, label studio is a flexible annotations system which supports annotations for a range of types of data including images and text. This module does a few steps to help process annotations produced through label studio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "label-studio init advert_annotations --template=image_classification --input-path=images --input-format=image-dir --allow-serving-local-files\n",
    "```\n",
    "\n",
    "```bash\n",
    "label-studio start ./advert_annotations\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_df(json_file):\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "        df = json_normalize(data,record_path=['completions'],meta=['data'])\n",
    "       # df['result'] = df['result'].apply(lambda x: return_choice(x[0]) if len([x][0]) ==1 else x)\n",
    "        df['result'] = df['result'].apply(lambda x: x[0]['value']['choices'] if len([x][0]) ==1 else x)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_completions(path):\n",
    "    filenames = glob(f'{path}/completions/*.json')\n",
    "    dataframes = [load_df(f) for f in filenames]\n",
    "    return pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created_at</th>\n      <th>id</th>\n      <th>lead_time</th>\n      <th>result</th>\n      <th>data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1602236711</td>\n      <td>379001</td>\n      <td>1.248</td>\n      <td>[text-only]</td>\n      <td>{'image': 'http://localhost:8081/data/upload/9...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": [
       "   created_at      id  lead_time       result  \\\n",
       "0  1602236711  379001      1.248  [text-only]   \n",
       "\n",
       "                                                data  \n",
       "0  {'image': 'http://localhost:8081/data/upload/9...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df = load_completions('../ph/ads/ad_annotations/')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created_at</th>\n      <th>id</th>\n      <th>lead_time</th>\n      <th>result</th>\n      <th>data</th>\n      <th>skipped</th>\n      <th>was_cancelled</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1596460221</td>\n      <td>3721001</td>\n      <td>8.94</td>\n      <td>[human, landscape]</td>\n      <td>{'image': '/data/vi_yes_ver01_data_sn84025841_...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": [
       "   created_at       id  lead_time              result  \\\n",
       "0  1596460221  3721001       8.94  [human, landscape]   \n",
       "\n",
       "                                                data skipped was_cancelled  \n",
       "0  {'image': '/data/vi_yes_ver01_data_sn84025841_...     NaN           NaN  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df = load_completions('../ph/photos/multi_label/')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _df_to_csv(df,out_fn):\n",
    "    df[['data','result']].to_csv(out_fn,header=['file','label',],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _df_to_json(df,out_fn):\n",
    "    df[['data','value.choices']].to_json(out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _df_to_pkl(df,out_fn):\n",
    "    df.to_pickle(out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_og_filepath(x):\n",
    "    \"\"\"\n",
    "    Transforms a filepaths from processed ImageStudio format back to the Orginal Newspaper Navigator filepath  format\n",
    "    \"\"\"\n",
    "    b, m, e = re.split('(_data_)',x)\n",
    "    m = m.replace('_','/')\n",
    "    e = re.split('(\\d{3}_\\d{1}_\\d{2}.jpg)',e)\n",
    "    return b+m+e[0].replace('_','/') +e[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def anno_sample_merge(sample_df: pd.DataFrame, annotation_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"anno_sample_merge merges a DataFrame containing a sample \n",
    "    from Newspaper Navigator and a DataFrame containing annotations\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_df : pd.DataFrame\n",
    "        A Pandas DataFrame which holds a sample from Newspaper Navigator Generated by `sample.nnSample()`\n",
    "    annotation_df : pd.DataFrame\n",
    "        A pandas DataFrame containing annotations loaded via the `annotate.nnAnnotations` class\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A new DataFrame which merges the two input DataFrames\n",
    "    \"\"\"\n",
    "    sample_df, annotation_df = sample_df.copy(), annotation_df.copy()\n",
    "    annotation_df['id'] = annotation_df['data'].map(lambda x:get_og_filepath(x))\n",
    "    return sample_df.merge(annotation_df, left_on='filepath',right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df= pd.read_csv('../ph/ads/sample.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class nnAnnotations:\n",
    "    def __init__(self, df):\n",
    "        self.annotation_df = df\n",
    "        self.labels = df['result'].unique()\n",
    "        self.label_counts = df['result'].value_counts()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f'{self.__class__.__name__}'\n",
    "                f' #annotations:{len(self.annotation_df)}')\n",
    "\n",
    "    @classmethod\n",
    "    def from_completions(cls, path, kind, drop_dupes=True, sample_df=None):\n",
    "        df = load_completions(path)\n",
    "        df = df.reset_index(drop=True) # add index\n",
    "        df['data']= df['data'].map(lambda x: x['image'])\n",
    "        df['data'] = df['data'].map(lambda x: x.split('?')[0])\n",
    "        df['data'] = df['data'].apply(lambda x: Path(x).name)\n",
    "        if any(df['data'].str.contains('-')): # removes labelstudio hash from data loaded via web interface\n",
    "            df['data'] = df['data'].str.split('-',expand=True)[1]\n",
    "        if drop_dupes:\n",
    "            df = df.drop_duplicates(subset='data',keep='last')\n",
    "        if kind=='classification':\n",
    "            empty_rows = df[df['result'].apply(lambda x:len(x)==0)].index\n",
    "            df = df.drop(empty_rows)\n",
    "            df['result'] = df['result'].map(lambda x: x[0])\n",
    "        if kind=='label':\n",
    "            df['result'] = df['result'].map(lambda x: \"|\".join(map(str,x)) if len(x) >=1 else x)\n",
    "            df['result'] = df['result'].map(lambda x:\"\" if len(x)==0 else x)\n",
    "        return cls(df)\n",
    "\n",
    "    def merge_sample(self, sample_df):\n",
    "        self.merged_df = anno_sample_merge(sample_df,self.annotation_df)\n",
    "\n",
    "    def export_merged(self, out_fn):\n",
    "        self.merged_df.to_csv(out_fn)\n",
    "\n",
    "    def export_annotations(self, out_fn):\n",
    "        df = self.annotation_df\n",
    "        if not Path(out_fn).exists():\n",
    "            Path(out_fn).touch()\n",
    "        suffix = Path(out_fn).suffix\n",
    "        if suffix == '.csv':\n",
    "            _df_to_csv(df, out_fn)\n",
    "        if suffix == '.json':\n",
    "            _df_to_json(df,out_fn)\n",
    "        if suffix == '.pkl':\n",
    "            _df_to_pkl(df,out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = nnAnnotations.from_completions('../ph/ads/ad_annotations/', 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnAnnotations #annotations:549"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filepath</th>\n      <th>pub_date</th>\n      <th>page_seq_num</th>\n      <th>edition_seq_num</th>\n      <th>batch</th>\n      <th>lccn</th>\n      <th>box</th>\n      <th>score</th>\n      <th>ocr</th>\n      <th>place_of_publication</th>\n      <th>geographic_coverage</th>\n      <th>name</th>\n      <th>publisher</th>\n      <th>url</th>\n      <th>page_url</th>\n      <th>created_at</th>\n      <th>id</th>\n      <th>lead_time</th>\n      <th>result</th>\n      <th>data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iahi_gastly_ver01/data/sn82015737/00279529091/...</td>\n      <td>1860-03-09</td>\n      <td>447</td>\n      <td>1</td>\n      <td>iahi_gastly_ver01</td>\n      <td>sn82015737</td>\n      <td>[Decimal('0.30762831315880534'), Decimal('0.04...</td>\n      <td>0.950152</td>\n      <td>['JTO', 'TMCE', 'An', 't%E', '3eott', 'County'...</td>\n      <td>Davenport, Iowa</td>\n      <td>['Iowa--Scott--Davenport']</td>\n      <td>Daily Democrat and news. [volume]</td>\n      <td>Maguire, Richardson &amp; Co.</td>\n      <td>https://news-navigator.labs.loc.gov/data/iahi_...</td>\n      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n      <td>1602237486</td>\n      <td>iahi_gastly_ver01/data/sn82015737/00279529091/...</td>\n      <td>0.838</td>\n      <td>text-only</td>\n      <td>iahi_gastly_ver01_data_sn82015737_00279529091_...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ohi_cobweb_ver04/data/sn85026050/00280775848/1...</td>\n      <td>1860-08-17</td>\n      <td>359</td>\n      <td>1</td>\n      <td>ohi_cobweb_ver04</td>\n      <td>sn85026050</td>\n      <td>[Decimal('0.5799164973813336'), Decimal('0.730...</td>\n      <td>0.985859</td>\n      <td>['9', 'BI.', 'I', '.QJtf', 'A', 'never', 'fall...</td>\n      <td>Fremont, Sandusky County [Ohio]</td>\n      <td>['Ohio--Sandusky--Fremont']</td>\n      <td>Fremont journal. [volume]</td>\n      <td>I.W. Booth</td>\n      <td>https://news-navigator.labs.loc.gov/data/ohi_c...</td>\n      <td>https://chroniclingamerica.loc.gov/data/batche...</td>\n      <td>1602236992</td>\n      <td>ohi_cobweb_ver04/data/sn85026050/00280775848/1...</td>\n      <td>7.593</td>\n      <td>illustrations</td>\n      <td>ohi_cobweb_ver04_data_sn85026050_00280775848_1...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": [
       "                                            filepath    pub_date  \\\n",
       "0  iahi_gastly_ver01/data/sn82015737/00279529091/...  1860-03-09   \n",
       "1  ohi_cobweb_ver04/data/sn85026050/00280775848/1...  1860-08-17   \n",
       "\n",
       "   page_seq_num  edition_seq_num              batch        lccn  \\\n",
       "0           447                1  iahi_gastly_ver01  sn82015737   \n",
       "1           359                1   ohi_cobweb_ver04  sn85026050   \n",
       "\n",
       "                                                 box     score  \\\n",
       "0  [Decimal('0.30762831315880534'), Decimal('0.04...  0.950152   \n",
       "1  [Decimal('0.5799164973813336'), Decimal('0.730...  0.985859   \n",
       "\n",
       "                                                 ocr  \\\n",
       "0  ['JTO', 'TMCE', 'An', 't%E', '3eott', 'County'...   \n",
       "1  ['9', 'BI.', 'I', '.QJtf', 'A', 'never', 'fall...   \n",
       "\n",
       "              place_of_publication          geographic_coverage  \\\n",
       "0                  Davenport, Iowa   ['Iowa--Scott--Davenport']   \n",
       "1  Fremont, Sandusky County [Ohio]  ['Ohio--Sandusky--Fremont']   \n",
       "\n",
       "                                name                  publisher  \\\n",
       "0  Daily Democrat and news. [volume]  Maguire, Richardson & Co.   \n",
       "1          Fremont journal. [volume]                 I.W. Booth   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://news-navigator.labs.loc.gov/data/iahi_...   \n",
       "1  https://news-navigator.labs.loc.gov/data/ohi_c...   \n",
       "\n",
       "                                            page_url  created_at  \\\n",
       "0  https://chroniclingamerica.loc.gov/data/batche...  1602237486   \n",
       "1  https://chroniclingamerica.loc.gov/data/batche...  1602236992   \n",
       "\n",
       "                                                  id  lead_time  \\\n",
       "0  iahi_gastly_ver01/data/sn82015737/00279529091/...      0.838   \n",
       "1  ohi_cobweb_ver04/data/sn85026050/00280775848/1...      7.593   \n",
       "\n",
       "          result                                               data  \n",
       "0      text-only  iahi_gastly_ver01_data_sn82015737_00279529091_...  \n",
       "1  illustrations  ohi_cobweb_ver04_data_sn85026050_00280775848_1...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations.merge_sample(sample_df)\n",
    "annotations.merged_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.export_merged('testmerge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "Path('testmerge.csv').unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created_at</th>\n      <th>id</th>\n      <th>lead_time</th>\n      <th>result</th>\n      <th>data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1602236711</td>\n      <td>379001</td>\n      <td>1.248</td>\n      <td>text-only</td>\n      <td>pst_fenske_ver02_data_sn84026497_00280776129_1...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1602237071</td>\n      <td>396001</td>\n      <td>0.870</td>\n      <td>text-only</td>\n      <td>scu_carlacox_ver01_data_sn84026965_00294551268...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": [
       "   created_at      id  lead_time     result  \\\n",
       "0  1602236711  379001      1.248  text-only   \n",
       "1  1602237071  396001      0.870  text-only   \n",
       "\n",
       "                                                data  \n",
       "0  pst_fenske_ver02_data_sn84026497_00280776129_1...  \n",
       "1  scu_carlacox_ver01_data_sn84026965_00294551268...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = nnAnnotations.from_completions('../ph/ads/ad_annotations/', 'classification')\n",
    "annotations.annotation_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\nConverted 01_sample.ipynb.\nConverted 02_annotate.ipynb.\nConverted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_completions(path, kind, drop_dupes=True):\n",
    "#     df = load_completions(path)\n",
    "#     df = df.reset_index(drop=True) # add index\n",
    "#     df['data']= df['data'].map(lambda x: x['image'])\n",
    "#     df['data'] = df['data'].map(lambda x: x.split('?')[0])\n",
    "#     df['data'] = df['data'].apply(lambda x: Path(x).name)\n",
    "#     if any(df['data'].str.contains('-')): # removes labelstudio hash from data loaded via web interface\n",
    "#         df['data'] = df['data'].str.split('-',expand=True)[1]\n",
    "#     if drop_dupes:\n",
    "#         df = df.drop_duplicates(subset='data',keep='last')\n",
    "#     if kind=='classification':\n",
    "#         empty_rows = df[df['result'].apply(lambda x:len(x)==0)].index\n",
    "#         df = df.drop(empty_rows)\n",
    "#         df['result'] = df['result'].map(lambda x: x[0])\n",
    "#     if kind=='label':\n",
    "#         df['result'] = df['result'].map(lambda x: \"|\".join(map(str,x)) if len(x) >=1 else x)\n",
    "#         df['result'] = df['result'].map(lambda x:\"\" if len(x)==0 else x)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# #old\n",
    "# def _process_completions(path, kind):\n",
    "#     df = load_completions(path)\n",
    "#     df['data']= df['data'].map(lambda x: x['image'])\n",
    "#     df['data'] = df['data'].map(lambda x: x.split('?')[0])\n",
    "#     df['data'] = df['data'].apply(lambda x: Path(x).name)\n",
    "#     if kind=='classification':\n",
    "#         df['value.choices'] = df['value.choices'].map(lambda x: x[0])\n",
    "#     if kind=='label':\n",
    "#         #df['value.choices'] = df['value.choices'].map(lambda x: \"|\".join(x))\n",
    "#         df['result'].map(lambda x: \"|\".join(map(str,x)) if len(x) >=1 else x)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old\n",
    "# def _load_df(json_file):\n",
    "#     with open(json_file) as f:\n",
    "#         data = json.load(f)\n",
    "#         df = json_normalize(data,record_path=['completions','result'],meta=['data'])\n",
    "#         return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnAnnotator",
   "language": "python",
   "name": "nnannotator"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
